{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running ensembles of SUMMA simulations\n",
    "\n",
    "`pysumma` offers an `Ensemble` class which is useful for running multiple simulations with varying options. These options can be parameter values, model structures, different locations made up of different file managers, or combinations of any of these. To demonstrate the `Ensemble` capabilities we will step through each individually. As usual we will begin with some imports and definition of some global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pysumma as ps\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "file_manager = 'PATH/TO/FILE_MANAGER'\n",
    "summa_exe = 'summa.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing decisions\n",
    "\n",
    "The `Ensemble` object mainly operates by taking configuration dictionaries. These can be defined manually, or can be defined through the use of helper functions which will be described later. For now, we will look at how to run models using different options for the `stomResist` and `soilStress` decisions. This is done by providing a dictionary of these mappings inside of a `decisions` key of the overall configuration. The `decisions` key is one of several special configuration keys which `pysumma` knows how to manipulate under the hood. We will explore the others later.\n",
    "\n",
    "This configuration is used to construct the `Ensemble` object, which also takes the SUMMA executable, a file manager path, and optionally the `num_workers` argument. The `num_workers` argument is used to automatically run these ensemble members in parallel. Here we define it as 2, since that's how many different runs we will be completing. You _can_ set this to a higher number than your computer has CPU cores, but you won't likely see any additional speedup by doing so.\n",
    "\n",
    "We then run the ensemble through the `run` method which works similarly to the `Simulation` object. After running the ensemble we check the status by running the `summary` method. This will return a dictionary outlining any successes or failures of each of the members. In the event of any failures you can later inspect the underlying `Simulation` objects that are internal to the `Ensemble`. We will demonstrate how to do this later in the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'run0': {'decisions':{'stomResist': 'Jarvis',\n",
    "                          'soilStress': 'NoahType'}},\n",
    "    'run1': {'decisions':{'stomResist': 'BallBerry',\n",
    "                          'soilStress': 'CLM_Type'}},\n",
    "}\n",
    "\n",
    "decision_ens = ps.Ensemble(summa_exe, config, file_manager, num_workers=2)\n",
    "decision_ens.run('local')\n",
    "print(decisions_ens.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Note in the previous example we didn't run every combination of `stomResist` and `soilStress` that we could have. When running multiple configurations it often becomes unwieldy to type out the full configuration that you are attempting to run, so some helper functions have been implemented to make this a bit easier. In the following cell we demonstrate this. You can see that the new output will show we have 4 configurations to run, each with a unique set of decisions. The names are just the decisions being set, delimited by `++` so that it is easy to keep track of each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisions_to_run = {\n",
    "    'stomResist': ['Jarvis', 'BallBerry'],\n",
    "    'soilStress': ['NoahType', 'CLM_Type']\n",
    "}\n",
    "\n",
    "config = ps.ensemble.decision_product(decisions_to_run)\n",
    "pprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Changing parameters\n",
    "\n",
    "Similarly, you can change parameter values to do sensitivity experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'run0': {'trial_params': {'windReductionParam': 0.1,\n",
    "                              'canopyWettingFactor': 0.1}}\n",
    "    'run1': {'trial_params': {'windReductionParam': 0.9,\n",
    "                              'canopyWettingFactor': 0.9}}\n",
    "}\n",
    "\n",
    "param_ens = ps.Ensemble(summa_exe, config, file_manager, num_workers=2)\n",
    "param_ens.run('local')\n",
    "print(param_ens.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "As you can tell, it can quickly become tiresome to type out every parameter value you want to set. To that end we also have a helper function for setting up these parameter sensitivity experiments. Now you can see that we will end up with 4 configurations, as before. We won't run this because it may take longer than is instructional. But, you can modify this notebook if you wish to see the effect each of these have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_to_run = {\n",
    "    'windReductionParam': [0.1, 0.9],\n",
    "    'canopyWettingFactor': [0.1, 0.9]\n",
    "}\n",
    "\n",
    "config = ps.ensemble.trial_parameter_product(parameters_to_run)\n",
    "pprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Running multiple sites via file managers\n",
    "\n",
    "As you may have guessed, you can also define an `Ensemble` by providing a list of file managers. This is useful for running multiple sites which can't be collected into a multi HRU run because they have different simulation times, are disjointly located, or for any other reason. It is important to note that in this case we don't provide the `Ensemble` constructor a `file_manager` argument, as it is now provided in the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'run0': {'file_manager': 'PATH/TO/FM0'},\n",
    "    'run1': {'file_manager': 'PATH/TO/FM1'},\n",
    "}\n",
    "\n",
    "manager_ens = ps.Ensemble(summa_exe, config, num_workers=2)\n",
    "manager_ens.run('local')\n",
    "print(manager_ens.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "managers_to_run = {\n",
    "    'file_manager': ['PATH/TO/FM0', 'PATH/TO/FM1']\n",
    "}\n",
    "\n",
    "config = ps.ensemble.file_manager_product(managers_to_run)\n",
    "pprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Combining ensemble types\n",
    "\n",
    "Each of these abilities are useful in their own right, but the ability to combine them into greater ensembles provides a very flexible way to explore multiple hypotheses. To this end we also provide a helper function which can facilitate running these larger experiments. We won't print out the entire configuration here, since it's quite long. Instead we show that this would result in 32 SUMMA simulations. For that reason we also won't run this experment by default, though you can if you wish to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ps.ensemble.total_product(dec_conf=decisions_to_run, \n",
    "                                   param_trial_conf=parameters_to_run, \n",
    "                                   fman_conf=managers_to_run)\n",
    "print(len(config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For illustrative purpose we show the first key of this configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(config.keys())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "As you can see, the keys (or names of the runs) grows when you include more options. This can be a problem for some operating systems/filesystems, along with being very hard to read. So, we also have a flag here that makes things more compact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ps.ensemble.total_product(dec_conf=decisions_to_run, \n",
    "                                   param_trial_conf=parameters_to_run, \n",
    "                                   fman_conf=managers_to_run,\n",
    "                                   sequential_keys=True\n",
    "                                  )\n",
    "print(list(config.keys())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Interacting with the underlying `Simulation` objects\n",
    "\n",
    "After all of the configuration madness it is probably worth figuring out how to actually deal with the simulations that get run via the `Ensemble`. To get back on track we'll just run the first decision ensemble again. Once it's been run and the summary reports success we can dig in deeper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'run0': {'decisions':{'stomResist': 'Jarvis',\n",
    "                          'soilStress': 'NoahType'}},\n",
    "    'run1': {'decisions':{'stomResist': 'BallBerry',\n",
    "                          'soilStress': 'CLM_Type'}},\n",
    "}\n",
    "\n",
    "decision_ens = ps.Ensemble(summa_exe, config, file_manager, num_workers=2)\n",
    "decision_ens.run('local')\n",
    "print(decisions_ens.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "To access the simulations individually you can use the `.simulations` attribute, which is simply a dictionary of the `Simulation` objects mapped by the `name` that's used to run the simulation. Let's loop through and print the decisions directly from the `Simulation` as proof things worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, sim in decision_ens.items():\n",
    "    print(f'{n} used {sim.decisions[\"stomResist\"]} for the stomResist option and {sim.decisions[\"soilStress\"]} for soilStress')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also provide some functionality to make it easier to wrangle the data together via the `merge_output` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_ds = decision_ens.merge_output()\n",
    "ens_ds['scalarLatHeatTotal'].plot.line(x='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "all",
   "language": "python",
   "name": "all"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
